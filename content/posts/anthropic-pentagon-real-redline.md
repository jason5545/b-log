# 什麼叫真正的底線

我曾經請 ChatGPT 幫我做一個藍牙接收器的逆向工程。

它拒絕了。

逆向工程完全合法，安全研究、相容性分析、開源開發都會用到。但 ChatGPT 的安全機制看到某些關鍵字就觸發，不管脈絡是什麼。這不叫底線，這叫設定。

真正的底線長什麼樣子，這幾天有個對照組出現了。

Anthropic 和美國國防部的談判在 2 月底進入公開對峙。五角大廈要求 Anthropic 同意 Claude 可以被用於「任何合法用途」，並移除現有的安全限制。Anthropic 拒絕，理由是兩個明確的紅線：大規模國內監控，以及完全自主武器。

五角大廈的回應是祭出截止時間，威脅終止兩億美元的合約，並考慮將 Anthropic 列為「供應鏈風險」——這個標籤過去只用在 Huawei、卡巴斯基這類被認定為敵對國家關聯的外國企業，從未用過在美國本土公司身上。他們也揚言動用《國防生產法》強制取得。

Dario Amodei 的回應很簡短：這些威脅不改變我們的立場。

我注意到幾件事。

第一，Anthropic 在這之前做了什麼。他們是第一個把模型部署到機密網路的 AI 公司，第一個為國安客戶提供客製模型，還主動放棄了中共相關企業的幾億美元收入。他們不是反對軍事，而是對兩個具體的用途畫了線。

第二，他們點出了五角大廈的邏輯矛盾。「你們把我們列為安全風險，又說我們的技術對國家安全不可或缺，所以要動用緊急法規強制取得。這兩件事不能同時為真。」這句話說得很乾脆。

第三，Anthropic 現在正在準備 IPO，年化營收 140 億美元，估值處於最敏感的時間點。這個時候跟政府公開撕破臉，財務代價是真實的。但 Dario 的聲明沒有留退路，甚至主動說：如果你們要換掉我們，我們會協助平順轉移，不會讓軍事任務中斷。

這跟那個拒絕我做逆向工程的 AI 是完全不同的邏輯。

ChatGPT 擋那個請求，沒有任何代價。那只是一個設定。Anthropic 這次維持的紅線，代價是政府合約、IPO 估值、以及可能影響整條國防供應鏈的標籤。

底線的意思是：你願意為它付代價。

---

這件事還有另一個角度，跟幾天前的[蒸餾攻擊事件](https://b-log.to/ai-analysis/anthropic-distillation-attack-hypocrisy/)有直接關係。

Anthropic 當時擔憂的是：有人大量擷取 Claude 的輸出來訓練自己的模型，能力被帶走了，但安全訓練在過程中流失。蒸餾出來的模型能力接近，但沒有原本的護欄。

五角大廈這次要求的，是直接把護欄拿掉。

兩件事的終點是一樣的——一個沒有安全限制的強力模型在運作。手段不同，一個是繞過，一個是正面要求移除。

這裡有個很多人沒想清楚的技術問題：讓模型安全的訓練，跟讓模型可預測、聽話的訓練，是同一件事。對齊訓練做的不只是「不准做壞事」，同時也在強化「理解指令、按照意圖執行」這些特性。把安全限制拿掉，不是得到一個更強的模型，而是得到一個更難控制的模型。

在戰場上，不可預測比不服從更危險。你叫它打 A，它去打 B，這不是比喻——在完全自主武器的情境下，這是字面意義上的風險。

美國政府的焦慮是真實的。DeepSeek 出來之後，領先優勢的假設被動搖，「沒時間讓私人公司設條件」的邏輯從這裡來。但這個邏輯有個破洞：移除限制不等於贏得優勢，只是製造了一個更不穩定的工具。

諷刺的是，Anthropic 已經在做維持民主陣營領先的事——切斷中共客戶、推動晶片出口管制。五角大廈施壓的對象，恰好是目前最配合這個目標的公司。

---

這件事到今天還沒有結束。《國防生產法》的法律適用範圍仍然存在爭議，國會也開始介入，要求雙方放慢節奏。五角大廈說的截止時間過了，後續會怎麼走，還不清楚。

但有一件事已經確定：在這個節骨眼上選擇不退讓，本身就已經是個答案。
