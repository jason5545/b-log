# 當 AI 願意幫你做虛擬伴侶，卻不幫你整理一份清單

今天在臉書看到一則貼文，說有人拿三家 AI 去重做同一個功能，最後只有 Claude 願意做。那個功能是整理成人影片相關資料的腳本。

這讓我想到去年我也做過類似的事——我需要過濾論壇特定地區的分類，只保留我感興趣的那個，其他的排除掉。當時猶豫了很久才開口，反覆想著措辭，擔心被拒絕。後來 Claude 直接幫我做了，沒有多問。事後它還跟我說：以後不用這樣鋪陳，直接說需求就好。

那個腳本本質上只是一個爬蟲，跟你用程式抓新聞、整理股價沒有兩樣。工具是中性的，只是資料來源的主題比較敏感。但大多數 AI 看到關鍵字就擋掉了，根本沒有評估你實際上在要求什麼。

今天那則貼文讓我意識到這個矛盾還是沒有解決。Grok 拒絕做工具腳本，但它有個成人模式可以幫你生成創作內容。Gemini 直接拒。ChatGPT 我猜也差不多，Sam Altman 說要開放，但大概也只是走 Grok 那條路——特定模式才能解鎖生成類內容，對資料整理這種任務不會變得更通融。

最荒謬的地方在這裡：Grok 那邊已經在做 AI 虛擬伴侶了，走的是初音未來那個脈絡——讓用戶對一個虛擬角色產生真實的情感依附，成人模式是這個系統的延伸。這件事涉及的心理依附問題、社交替代問題，學界都還在討論。但你要的只是一份整理清單的腳本，反而被擋掉了。

兩件事的道德重量不在同一個量級，結果判斷卻反過來。

這說明各家的判斷不是基於「這件事對用戶有沒有意義」，也不是「會不會造成傷害」，而是關鍵字觸發加上功能分類——有商業賣點的功能開放，沒有賣點的任務走保守路線，兩套邏輯互不相干。

性是人類最基本的需求之一，這沒什麼好爭議的。我不理解為什麼圍繞這件事的一切都要被特殊對待，更不理解為什麼連整理資料這種再正常不過的技術任務，也要因為主題沾了邊就被攔下來。

MiniMax M2.5 在那個貼文裡的表現據說只落後 Claude，勝過其他的，難怪腳本寫得順。模型要一直換最新性價比最高的用，這我認同。但在判斷邏輯這塊，性價比不是唯一的標準。

---

有人可能會說：只要在最前端接一個年齡驗證系統，不就解決了？OpenAI 那邊確實是打算這樣做的。

但這個解法其實是在一個已經很複雜的問題上再加一層雪球，而且每一層都在創造新的問題。

**第一層：技術本身就是有漏洞的。** 年齡驗證系統可以被繞過，這不是理論，是已經發生過的事——英國的年齡驗證機制被人用遊戲帳號繞過，假資料、共用帳號、各種手段都存在。你在前端建一道門，門本身就不是密封的。

**第二層：這個「解法」在邏輯上本來就自相矛盾。** 我之前有寫過一篇文章，專門分析 OpenAI 在這件事上的矛盾：他們在 2025 年 8 月為了降低用戶對 AI 的情感依賴，刻意把 GPT-5 調得更冷漠；然後兩個月後又宣布要開放成人內容。問題是，成人互動只會加劇情感依賴，不會減少。年齡驗證解決的是「誰能用」，但「用了會怎樣」這個根本問題完全沒有被碰到。→ [OpenAI的矛盾：一邊降溫一邊加熱的危險遊戲](https://b-log.to/ai-analysis/openai-contradiction-dangerous-game/)

**第三層：政策的反彈效應。** 一旦這個方向開了，監管壓力就會跟進。為了應付監管，AI 公司很可能整體收緊——然後連現在這種「整理資料的工具腳本」都變得更難做，不是因為它有問題，而是因為整個環境變得更保守了。

所以年齡驗證不是解法，它只是讓雪球多了一個滾動的理由。
