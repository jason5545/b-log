# Anthropic 說別人蒸餾是攻擊，但他們自己封鎖中國、沒有開源模型


Anthropic 昨天發了一篇 blog，說他們偵測到 DeepSeek、Moonshot、MiniMax 對 Claude 發動「工業規模蒸餾攻擊」。24,000 個假帳號、1,600 萬次 exchange。數字很嚇人。

我看完之後覺得，這篇文章的問題比它指控的行為還要多。

## 150,000 次，很多嗎？

Anthropic 說 DeepSeek 跟 Claude 交互超過 15 萬次。

T3 Chat 是 Theo 做的 AI 聊天 App，支援多個模型，用戶不算少。他說他的網站一天就能跑到這個數字。

那 T3 Chat 也算在攻擊嗎？

MiniMax 那 1,300 萬次就更荒謬了。今天你要跑 SWE-bench，要測試一個模型的 coding 能力，你當然要拿市場上所有主流模型一起比。反覆跑、調整 prompt、出報告，這本來就是做 benchmark 的標準流程。數字很容易堆上去。

這難道也叫攻擊？

## MCP 讓「次數」這個指標徹底失效

現在 agentic AI 是常態。

一個用戶發一條訊息，背後可能觸發十幾次 MCP tool call，每次 call 又產生新的模型回應。對用戶來說是「問了一個問題」，對 Anthropic 的系統來說是幾十次 exchange。

用次數來判斷意圖，在 2026 年根本沒有意義。

## 假帳號是你們逼的

Anthropic 說假帳號是惡意的證據。

但 Anthropic 自己把中國流量全封鎖了。沒有合法管道，想用 Claude 的中國開發者要怎麼辦？當然只能找代理服務、用假帳號繞進來。

你不讓我進門，我翻牆進來，然後你說我是小偷。

一個中國新創團隊，想在自己的產品裡對比幾個模型的表現，正常流程是什麼？沒有正常流程。所以他們的行為模式，跟 Anthropic 描述的「攻擊」長得一模一樣。根本無法區分。

## 黃金還是黃金

Anthropic 說蒸餾出來的開源模型很危險，因為安全防護會被濾掉。

Theo 的比喻是：蒸餾就像用篩子在沙子裡篩黃金。如果你做得夠好，黃金還是黃金，不會因為這層篩網而變質。

如果蒸餾一下安全機制就掉了，問題不在蒸餾技術，問題在那個安全機制本來就只是表面貼上去的。

而且 Anthropic 自己也在蒸餾自己的模型，做成更小更便宜的版本。那他們蒸餾出來的版本，安全機制是完整的嗎？

## 這篇 blog 的真正目的

DeepSeek V4 快出來了。據說 coding 能力會超過 Claude。

Anthropic 這篇文章裡，花了很大篇幅呼籲晶片出口管制、要求政策制定者介入、說這是國家安全問題。

技術上開始有壓力，然後跑去找政治人物。

而且 Anthropic 目前沒有任何開源模型。連 OpenAI 都已經有了。Meta 的 Llama 跑得很好。DeepSeek 本身就是開源的。

一家沒有開源模型的公司，跑去呼籲治理開源模型。開源本來的精神就是任何人都可以拿去用、改、蒸餾、再發布。這不是漏洞，這是設計。

你要治理的話，說穿了就是「開源這件事本身有問題」。

所以這篇 blog 的完整邏輯是：技術競爭輸了，包裝成安全議題，去推動對自己有利的監管，在 DeepSeek V4 出來之前先射一箭。

每一根柱子都在搖，但包裝得很好看。

