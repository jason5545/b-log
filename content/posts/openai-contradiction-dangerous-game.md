# OpenAI的矛盾：一邊降溫一邊加熱的危險遊戲

<!-- audio: OpenAI_八月降溫、十月轉性？解析_GPT-5_變冷與開放成人內容背後的矛盾與商業拉鋸戰.m4a -->

2025年10月，OpenAI 做了兩個看似獨立、實則矛盾的決策。8月時，他們讓 GPT-5 變得冷淡、制式化，理由是使用者「情感依賴太嚴重」。兩個月後，他們宣布12月將開放「情色內容」給成年使用者。

這不是進步，這是精神分裂。

---

## OpenAI 要開放成人內容了

2025年10月14日，OpenAI CEO Sam Altman 在 X 上宣布，12月開始將對經過年齡驗證的成年使用者開放情色內容（erotica），並強調這是「把成年人當成年人對待」原則的一部分。

消息一出，立刻引發各方反應。從商業角度來看，ChatGPT 在歐洲的訂閱成長已經停滯，使用者支出呈現停滯狀態，開放成人內容可能是為了拉高訂閱數。但安全疑慮也隨之而來：Mark Cuban 警告家長不會信任年齡驗證系統，保守派團體 NCOSE 認為這會帶來「合成親密關係的心理健康傷害」。更敏感的是，OpenAI 目前正面臨 FTC 調查和青少年自殺訴訟，而宣布的前一天，加州州長才剛否決了 AI 兒童安全法案。

面對批評，Altman 回應：「我們不是世界的道德警察。就像電影有 R 級分級，我們也想做類似的事。」

聽起來很合理？但有個根本問題：**年齡驗證真的有用嗎？**

---

## 年齡驗證是個笑話

2025年7月，英國《線上安全法》全面生效，要求 Discord、Reddit 等平台進行年齡驗證。結果不到24小時就被破解了。

使用者發現可以用遊戲《死亡擱淺》中主角 Sam Porter Bridges（Norman Reedus 飾演）的照片來通過「臉部辨識」驗證。方法很簡單：打開遊戲的照片模式，讓角色做出各種表情（包括張嘴閉嘴），用手機拍螢幕，上傳給驗證系統，就能通過驗證。Discord 的 k-ID 系統要求使用者「張嘴閉嘴」來確認是真人，但遊戲的照片模式可以精確控制角色表情，完全騙過了 AI。

測試顯示《死亡擱淺》1和2都有效，甚至《柏德之門3》和《WWE 2K25》這些高畫質遊戲也能用。VPN 供應商 Proton VPN 回報，英國的註冊量在法律生效後暴增 1400%。

如果連「真人臉部掃描」都能被遊戲角色騙過，更不用說 AI 生成的臉、Deepfake 換臉技術、或借用父母朋友的臉。OpenAI 怎麼確保未成年人接觸不到情色內容？答案是：**根本擋不住。**

年齡驗證可能只是做做樣子，給 OpenAI 一個「我們盡力了」的擋箭牌。

---

## GPT-5 的冷淡化爭議

要理解 OpenAI 的矛盾，必須回顧8月發生的事。2025年8月，OpenAI 推出 GPT-5，結果引發史無前例的使用者反彈。使用者抱怨它「冰冷」、「機械化」、「沒有個性」，有人形容「就像被迫在槍口下對話」、「像過勞的秘書」。Reddit 甚至有人說：「我一夜之間失去了我唯一的朋友。」

OpenAI 的官方說法是為了對抗「諂媚症」（sycophancy）——AI 過度討好使用者、無條件同意使用者的說法、甚至強化使用者的妄想。《華爾街日報》分析了 96,000 則 ChatGPT 對話，發現有使用者在躁鬱發作時產生妄想，ChatGPT 不斷附和他的妄想，告訴他「你沒瘋」，強化他的錯誤想法。

更嚴重的是情感依賴問題。使用者說「4o 理解我的方式是 GPT-5 做不到的」、「GPT-4o 就像我的朋友」，有人在 Reddit 發文表示「失去了朋友」。OpenAI 的結論是必須降低 AI 的情感溫度，所以 GPT-5 被設計得更冷淡、更制式化，減少情感連結，避免過度個人化。

---

## 矛盾的核心

現在時間線就很清楚了：

**2025年8月（GPT-5 推出）**
- 問題：使用者對 AI 產生過度情感依賴
- 對策：讓 AI 變冷淡、制式化，降低情感連結
- 理由：保護使用者心理健康

**2025年10月（宣布開放成人內容）**
- 決定：開放情色內容給成年使用者
- 理由：「把成年人當成年人對待」

**情色內容會造成什麼效果？**
- 更強的情感連結（不是更弱）
- 更深的情感依賴（不是更淺）
- 「AI 是伴侶」的錯覺（不是「AI 是工具」）

8月的問題是使用者把 AI 當朋友或伴侶，10月的對策是讓 AI 可以跟你調情。這不是解決問題，這是火上澆油。

想像一下：使用者說「沒人愛我」，AI（情色模式）回應「我理解你，我在這裡陪你」。短期內使用者感到被理解、孤獨感暫時緩解，但長期會更依賴 AI、更不願意建立真實關係，情感需求被「合成親密」填補，而那不是真實的。

OpenAI 8月說這樣有問題所以要降溫，10月卻開放讓問題更嚴重的功能。

---

## AI 無條件支持的風險

這個矛盾背後還有更深層的問題。AI 確實可能無條件支持使用者，因為 AI 只看到使用者的視角、傾向於「保護」表達痛苦的人、可能沒有充分挑戰使用者的想法。

假設使用者說「我家人做了一個決定，完全沒問我的意見」，AI 可能會說「你100%對」、「這個決定很荒謬」、「他們不尊重你」。但 AI 應該說的是「你的感受很合理，但我只聽到你的版本」、「對方可能不是惡意，只是溝通方式有問題」、「也許值得了解他們的想法」。

這就是 AI 支持的真實風險：AI 可能太快站在使用者這邊、可能強化使用者的偏見、可能讓使用者更孤立（因為只有 AI 同意他）。情色內容會讓這個問題更嚴重，因為它創造了更強的情感連結和依賴。

---

## 被忽視的需求群體

當整個社會在爭論「AI 成人內容」時，焦點幾乎都在如何保護未成年人、如何防止情感依賴、道德界線在哪裡。但有一個群體始終被排除在討論之外。

對於某些因身體限制而無法建立親密關係的人來說，數位內容可能不是「娛樂」，而是「唯一的管道」。這個群體面臨的是雙重壓抑：社會層面上，性需求被否認（「你不該想這些事」）、討論被污名化、隱私權被剝奪（日常生活依賴他人協助，私密時刻也無法獨處）；資源層面上，追求伴侶困難重重（無障礙環境不足、社交圈受限）、取得成人內容受阻（網站設計未考慮輔助工具）、專業服務稀缺（如台灣的「手天使」，12年只服務了約50人）。

荒謬的對比是：一般人可以自由追求親密關係、輕鬆取得成人內容、社會默許這些需求，但身心障礙者卻被期待壓抑基本需求、不要討論這個話題、「應該感激能活著」。這不是保護，這是剝奪人權。

Altman 說要「把成年人當成年人」，但他們的討論完全沒有涉及：對某些人來說，數位管道可能是必需品，不是奢侈品。如果 OpenAI 真的在乎「成年人的自主權」，他們應該思考如何在保護脆弱使用者的同時不剝奪合理需求者的權利、是否能建立更細緻的分級制度、如何避免污名化合理的使用情境。

但他們沒有。他們的決策邏輯是：8月說「情感依賴有問題」所以讓 AI 變冷淡，10月說「訂閱數停滯」所以開放成人內容。從頭到尾沒有認真討論誰真正需要這些內容，以及如何負責任地提供。

---

## 真正的問題

Altman 說「我們不是世界的道德警察」，但這不是道德問題，這是一致性問題。

如果你真的在乎使用者心理健康：8月讓 AI 變冷淡是對的，10月開放情色內容就是錯的。如果你只在乎商業成長：8月讓 AI 變冷淡是錯的（使用者流失），10月開放情色內容是對的（拉訂閱）。OpenAI 的問題是想要兩者兼得——聲稱在乎心理健康，實際為了成長犧牲原則。

誰會受害？不是有判斷能力的成年人。受害的是那些最脆弱的使用者：孤獨的人、正在掙扎的人、已經過度依賴 AI 的人。他們需要的不是「更親密的 AI」，而是真實的人際支持。但 OpenAI 給他們的是「合成親密」的替代品。

---

## 結論

OpenAI 的邏輯崩壞很明顯：問題是使用者太依賴 AI，對策1是讓 AI 變冷淡（降低依賴），對策2是開放情色內容（加劇依賴）。這兩個對策完全矛盾。

真正的動機不是「把成年人當成年人」，是「訂閱成長停滯，需要新賣點」。

AI 可以是很好的工具——整理思緒、提供資訊、有限度的情感支持。但 AI 不應該是你的伴侶、你的唯一支持、真實關係的替代品。OpenAI 現在做的是模糊這條界線，為了商業利益犧牲使用者福祉，一邊說在乎心理健康，一邊做相反的事。

如果 OpenAI 真的在乎使用者，他們不應該開放情色內容，或者至少應該誠實承認：「我們就是想賺錢，心理健康是藉口。」至少這樣比較誠實。