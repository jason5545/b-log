# AI 價值鏈大洗牌：從四件事看懂 2026 年開局的產業地震

2026 年才剛開始，AI 產業就丟出了四顆震撼彈。乍看之下是四條獨立新聞，但我把它們攤開來看，發現講的其實是同一個故事。

## 軟體股的血洗

2 月初，美股 AI 相關股票一片慘綠。導火線看似很小——Anthropic 發布了一個法律文書自動化工具。結果 Thomson Reuters、Legalzoom 等公司股價單日跌超 12%，PayPal、Expedia、Intuit 跌幅超過 10%，軟體和金融數據類股合計蒸發約 3,000 億美元市值。

連晶片股都沒能倖免。AMD 財報其實超出預期，但展望不夠亮眼，股價暴跌 17%，創七年來最大跌幅。NVIDIA 連續四天下跌，累計跌了近一成。

市場在恐慌什麼？一句話：**AI 已經強到可以取代軟體公司了，而且不是未來式，是現在進行式。**

## Anthropic 的 TPU 豪賭

往回看幾個月，2025 年 10 月 Anthropic 宣布大幅擴展 Google Cloud TPU 的使用規模，最多存取 100 萬顆 TPU 晶片，2026 年上線超過 1GW 算力。12 月 Broadcom 的財報電話會上揭露，Anthropic 就是那個神秘的百億美元 TPU 訂單客戶，而且又追加了 110 億美元。

但這不是「棄 GPU 改 TPU」。Anthropic 採取的是三平台並行策略——Google TPU 負責一部分訓練和推論、Amazon Trainium 負責 Project Rainier 超算叢集、NVIDIA GPU 處理其餘工作負載。哪個平台性價比最好，就把對應的任務丟過去。

這個策略的潛台詞很清楚：**GPU 不再是唯一選擇，專用晶片在推論場景的性價比已經超過通用 GPU。**

## NVIDIA 買下 Groq 的真正意圖

2025 年聖誕夜，NVIDIA 以 200 億美元現金拿下 Groq 的資產和核心團隊，創下公司史上最大交易紀錄。交易結構很聰明——名義上是「非專屬授權協議」加上人才收編，Groq 法人實體保持獨立，藉此繞過反壟斷審查。

Groq 的 LPU（Language Processing Unit）架構跟 GPU 完全不同。GPU 靠硬體動態排程，LPU 靠編譯器在執行前就把每一步都排好，達到確定性執行。跑大型語言模型推論時，LPU 每秒可輸出 300 到 500 個 token，延遲極低。代價是單顆晶片只有 230MB SRAM，要跑一個 70B 模型得串接數百顆，初始建置成本高。但在高流量場景下，每 token 營運成本反而更低。

美銀分析師說得直白：這筆交易代表 NVIDIA 承認，GPU 主宰了訓練市場，但推論市場需要不同的東西。

## 記憶體：AI 的氧氣正在窒息

如果晶片是 AI 的大腦，記憶體就是 AI 的氧氣。而現在，這個氧氣正在嚴重短缺。

Micron 在 2026 財年第一季交出了驚人的成績單——營收 136.4 億美元，年增 57%，毛利率衝上近 57%。更關鍵的是，Micron 的 HBM（高頻寬記憶體）產能整個 2026 年已經全部售罄，大部分訂單的價格都已鎖定。SK Hynix 的狀況也一樣，2026 年的 HBM 產能早就被 NVIDIA 等大客戶搶光，甚至在 HBM4 上拿到了比 HBM3E 高出約 50% 的價格溢價。

HBM 為什麼這麼缺？因為製造一個單位的 HBM 需要犧牲三個單位的標準 DRAM 產能。當所有記憶體廠商都把產能優先分配給 AI 資料中心，消費端的記憶體供給就被嚴重壓縮。2025 年記憶體價格飆漲了 246%，DRAM 庫存從 2024 年底的 17 週降到只剩 2 到 4 週。NVIDIA 甚至因為 GDDR7 短缺，計畫在 2026 上半年將 RTX 50 系列 GPU 產量砍掉 30% 到 40%。Micron 的 CEO 直接說：供給遠遠跟不上需求，而且這個狀況會持續到 2026 年之後。

台股這邊更慘烈。2 月 2 日，市場傳出中國長江存儲將把原訂 2027 年量產的武漢新廠提前到 2026 下半年，NAND Flash 族群出現「史詩級崩跌」——群聯、華邦電、南亞科、力積電全部亮燈跌停，旺宏、威剛跌幅超過 8%。諷刺的是，同一天韓國的 SK 海力士漲了 7.5%、三星漲近 7%、鎧俠漲約 9%，完全無視這個消息。

這個分化很說明問題：掌握 HBM 先進製程和 AI 資料中心訂單的韓系大廠屹立不搖，而以傳統 NAND 和消費級 DRAM 為主的台系廠商則被恐慌情緒擊潰。市場在用腳投票告訴你，記憶體產業的價值正在從「量」轉向「質」——誰能做 HBM，誰就掌握定價權。

現在回頭看 NVIDIA 收購 Groq，多了一層含義。Groq 的 LPU 用的是晶片內建的 SRAM，完全不需要外部 HBM。當全世界都在搶 HBM 搶到頭破血流的時候，一個不依賴 HBM 的推論架構，其戰略價值就更加明顯了。NVIDIA 花 200 億買的不只是速度，還是一張繞過記憶體瓶頸的保險單。

## 四件事，一個故事

把這四件事串起來，我看到的是一條因果鏈：

**AI 能力越強 → 推論需求爆發 → 專用晶片崛起挑戰 GPU 壟斷 → 記憶體成為最大瓶頸 → 不依賴 HBM 的架構獲得戰略溢價 → 推論成本終將下降 → 軟體公司被取代的速度加快 → 整條價值鏈重新洗牌。**

最上游，記憶體成了 AI 的命門。HBM 供不應求、價格飆漲，做一個單位的 HBM 要犧牲三個單位的普通 DRAM，連消費級 GPU 的產量都被迫縮減。這個物理限制短期內無解。

算力層，架構正在分裂。Anthropic 押注 TPU，NVIDIA 買下 Groq 的 LPU，兩者都在說同一件事：推論市場需要不同於訓練的專用架構。而 Groq 的 SRAM 路線更直接繞過了 HBM 瓶頸，這在記憶體全面短缺的背景下格外有戰略意義。

下游，軟體公司被市場提前判了死刑。推論基礎設施到位意味著 AI agent 跑得越來越快、越來越便宜，取代傳統軟體的門檻正在快速降低。

而台股記憶體族群的崩跌則揭示了另一條裂縫：在 AI 重新定義記憶體價值的時代，有 HBM 能力的廠商和沒有的廠商，命運正在快速分化。

## 我的觀察

這波恐慌的方向是對的，但幅度可能過頭。Anthropic 出個法律工具就讓一票公司蒸發 3,000 億美元，PayPal 跟 Thomson Reuters 被同等對待，這顯然是情緒驅動的無差別拋售。不同公司被 AI 取代的難度和時間表差異很大，市場一刀切不合理。

另一個矛盾點：如果 AI 強到能取代一堆軟體公司，那做 AI 基礎設施的公司應該更值錢，但它們也在跌。這說明市場現在不是在理性定價，而是在「先跑再說」。

記憶體的故事則更複雜。台股記憶體族群因為長江存儲提前量產的消息崩跌，但同一天韓系大廠全面大漲，說明市場其實看得很清楚——AI 時代的記憶體價值在 HBM，不在傳統 NAND 和消費級 DRAM。有能力做 HBM 的廠商享受前所未有的定價權，沒有的則面臨被邊緣化的風險。而 Groq 的 SRAM 路線如果真的規模化成功，甚至可能開闢出一條完全繞過 HBM 的推論路徑，那又是另一層重新定價。

不過長期來看，有一件事幾乎確定：**推論成本只會越來越低，AI 能做的事只會越來越多。** 那些靠整理和呈現資訊賺錢、但沒有不可替代資料壁壘的中間層公司，壓力只會越來越大。

2026 年的 AI 產業，正在從建設期進入應用期。上一輪的贏家不一定是下一輪的贏家，而這場洗牌才剛開始。
