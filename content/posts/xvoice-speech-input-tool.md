# 我為什麼要做 XVoice：一個為「發音不標準」的人設計的語音輸入工具

## 起因

身為一個每天打字超過八小時的開發者，我一直對語音輸入抱有期待。但每次嘗試市面上的語音輸入工具，結果都讓我很挫折——我的發音不夠標準，辨識率慘不忍睹。

「專案」變成「專欄」、「不過」變成「如果」、「30巷」變成「上直」⋯⋯這些錯誤讓我花更多時間修正，比直接打字還累。

於是我決定自己做一個。

## 核心概念：Whisper + LLM 雙層修正

XVoice 的設計理念很簡單：**既然單靠語音辨識不夠準，那就讓 LLM 來幫忙修正。**

流程是這樣的：

```
麥克風 → VAD 偵測語音 → Whisper 辨識 → 簡繁轉換 → 信心度判斷 → LLM 修正 → 輸出
```

當 Whisper 對自己的辨識結果信心不足時，就會送給 LLM 做二次修正。LLM 會根據上下文語意，把那些「聽起來像但意思不對」的同音字錯誤修正過來。

## 技術選擇

- **VAD**：Silero VAD，輕量又準確，靜音 1 秒自動送出
- **STT**：faster-whisper large-v3，用 CTranslate2 加速，本地 GPU 推論
- **LLM**：透過 OpenRouter 呼叫 Claude Haiku 4.5，便宜又快
- **簡繁轉換**：OpenCC s2twp 模式，自動把簡體轉成臺灣用語
- **輸入模擬**：KDE Wayland 用 kwtype，X11 用 xdotool

## Whisper 調校心得

用 large-v3 模型配合以下參數，辨識率有明顯提升：

- `beam_size: 10`：增加搜尋寬度
- `best_of: 3`：多次採樣取最佳
- `temperature: 0.0`：確定性輸出，減少隨機錯誤
- `condition_on_previous_text: false`：避免錯誤累積
- `initial_prompt`：提供常用詞彙提示

另外，Whisper 有時會產生「幻覺」輸出，例如「MING PAO」、「多謝收睇」、「字幕由...提供」這類莫名其妙的文字。解法是在辨識結果層直接過濾這些已知的幻覺模式。

## 信心度判斷機制

不是每句話都需要 LLM 修正。判斷邏輯：

1. **純英文/數字**：直接輸出，不送 LLM（英文辨識準確度本來就不錯）
2. **含中文**：根據 Whisper 回報的信心度指標判斷
   - `avg_logprob`：平均對數機率，越接近 0 越有信心
   - `no_speech_prob`：非語音機率，越低越確定是人聲

信心度高就直接輸出，低才送 LLM 修正。這樣可以節省 API 費用，也加快響應速度。

## Linux Wayland 的坑

在 KDE Wayland + fcitx5 環境下，kwtype 輸入英文和數字會被輸入法攔截，跑進輸入法的候選框裡。

一開始嘗試用 `fcitx5-remote -c` 暫停輸入法，但效果不穩定。最後的解決方案很簡單：在 fcitx5 加入一個英文鍵盤輸入法，平常切換到英文鍵盤，需要打中文時再切到 Rime。這樣 kwtype 就能正常輸出所有字元了。

## 實際使用體驗

按下 `Ctrl+Alt+V` 開始錄音，說完話後靜音 1 秒自動送出。文字會直接輸入到當前游標位置，不管是在 VS Code、瀏覽器還是任何應用程式。

也可以用 `Win+H` 呼叫一個類似 Windows 語音輸入的浮動視窗，隨時可見錄音狀態。

## 成本估算

使用 Claude Haiku 4.5 透過 OpenRouter：

- 每次修正約 400-500 tokens
- 每次約 $0.0005 美金
- 每天 100 次使用，月成本約 $1.5 美金

對於個人使用來說非常划算。

## 記錄與調校

為了持續改進辨識品質，每次語音輸入都會記錄到本地 SQLite 資料庫：

- 原始辨識結果和信心度指標
- 是否經過 LLM 修正
- 最終輸出文字

累積一段時間的資料後，就能分析哪些情況辨識不準、LLM 使用率是否合理，然後調整信心度閾值等參數。

## 給發音不標準的你

如果你也曾經對語音輸入感到挫折，XVoice 或許值得一試。它不會讓辨識率達到 100%，但至少能把那些惱人的同音字錯誤降到可以接受的程度。

專案開源在 GitHub，歡迎試用和貢獻。
