# AI 幫我畫了一架引擎掛反的飛機

今天中午寫了一篇模擬飛行的文章，需要封面圖。

想說用 AI 生一張。快、方便、效率高。輸入 prompt，幾秒鐘就有一張華航 777 在桃園機場的圖。雨天黃昏，地面濕滑有反光，氛圍超對。

發文，上班去了。

結果被人戳。

「你那個引擎掛架是反的。」

回去一看。真的。GE90 的掛架方向完全搞反。然後尾翼的位置也不對。用人類來比喻的話，就是頭長在屁股的位置。

氛圍對，細節全崩。

更令人混淆的是，它機身上的塗裝和文字是完美的。過去 AI 最不擅長的「拼寫」，現在卻變成了它的強項。它懂「符號的形狀」（2D 像素排列），所以能畫出完美的文字；但它不懂「物體的運作」（3D 物理邏輯），所以搞反了掛架。

讀者看到尾翼上的梅花畫對了，潛意識就更信任這張圖的真實性。

這是一種視覺上的權威性詐欺。當我們看到鉚釘清晰、光影完美的 4K 圖像時，大腦會被這些高頻細節欺騙，下意識認為「畫得這麼細，結構一定沒問題」。它用完美的材質，掩蓋了邏輯的荒謬。

它不懂「飛機是什麼」。它只是把像素拼成看起來像飛機的東西。引擎怎麼掛、尾翼朝哪邊，這種結構邏輯它沒有概念。

對不懂的人來說，這是一張好看的圖。對模擬飛行圈來說，這是常識性錯誤。比波音 vs 空巴的爭論嚴重多了——那是偏好問題，這是「這根本不是飛機」的問題。

發出去，就證明了連我也看不出來。

社群的反應更加強了這個現象。Reddit 上充滿了「太逼真了好可怕」、「分不出真假」的讚嘆。評論家盛讚它的「物理精確光影」（Physics-Accurate Lighting）和攝影棚等級的質感。

大眾被照片級的光影與材質嚇到了，恐懼與讚美皆來自於表面的真實。卻鮮少有人討論那些違反物理定律的怪異細節。

恐懼來自於表面的真實，盲點來自於對邏輯的忽視。

---

那個模型是 Google 的 Nano Banana Pro。

就是那個在 LMArena 匿名評測奪冠、Google 順勢拿來大肆行銷的「最強生圖 AI」。正式名稱是 Gemini 3 Pro Image，但因為評測時用「nano-banana」這個代號，結果社群爆紅，Google 就繼續用這個名字宣傳。

最諷刺的是，這個模型的官方行銷主打特色竟然是「Physics-Aware Reasoning」（物理感知推理）和「Deep Thinking」（深度思考）。Google 宣稱它能理解重力、因果邏輯，在繪圖前會先「思考」物體的物理結構。

排名第一，然後畫出引擎掛反的飛機。

在 LMArena 上讓人類盲測投票，「看起來漂亮」的分數可以很高，但結構對不對、細節合不合理，評測根本不管。對不懂飛機的評審來說，引擎掛反了也是一張好看的圖。

這解釋了為什麼它能拿第一：因為評審大眾也不懂飛機。這是一場由外行人舉辦、讓外行人投票、選出最能騙過外行人的比賽。

為什麼會這樣？這不是 Bug，這是目前 AI 架構的本質特徵。

所有的生成式 AI，學的都是「像素的統計關聯」（Correlation），而不是「物理的因果邏輯」（Causality）。

文字、金屬光澤、鉚釘細節，這些屬於「局部特徵」（Local Features）。在統計上，它們的規律很強，很容易模仿。但「引擎掛在機翼下」屬於「拓撲結構」（Topological Structure）。這需要理解物體的 3D 空間關係。但 AI 的訓練資料全是 2D 照片，它根本沒見過 3D 的飛機。

它就像一個只看過照片、從沒摸過實物的畫家。它可以把照片臨摹得惟妙惟肖，但因為不知道那其實是一個立體的金屬圓柱體，所以把它畫歪了也不自知。

只要我們還停留在「用 2D 圖片訓練 AI」的典範裡，這個問題就永遠無解。這不是算力多寡的問題，這是維度缺失的問題。

後來我回家開了 MSFS，自己截了一張駕駛艙視角的圖。777，夜間，跑道對正。PFD、ND、MCP 都在該在的位置。沒那麼「藝術」，但至少是對的。

以後不會再為了求快用 AI 生這種圖了。反正文章又不會跑掉。
