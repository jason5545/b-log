# Anthropic 這次真的搞砸了

這幾天 Anthropic 搞出一個讓整個開發者社群炸鍋的事：他們在 1 月 9 日，零預警地封鎖了所有透過第三方工具（像是 OpenCode）使用 Claude Max 訂閱的帳號。沒有公告，沒有遷移期，付著 $200 美金月費的開發者，工作到一半直接被踢出去。

更離譜的是，一開始的處理方式是直接封帳號。等到 GitHub、Reddit、Hacker News 全部炸開，他們才解封，然後說「我們會把 ToS 寫清楚」。所以規則本來根本沒寫清楚，你憑什麼封人？

YouTuber Theo 在今天發了一支影片罵這件事。他幾天前才連續發影片稱讚 Claude 是目前最強的程式開發模型，沒有之一。結果現在說要取消訂閱了。他講了一句很痛的話：「你們又不是 Apple。」Apple 可以這樣搞，是因為有硬體綁定、生態系護城河、十幾年的使用者鎖定。Anthropic 有什麼？模型好一點？這個領先可能只剩幾個月。DeepSeek、Llama、Mistral 都在追。開發者社群的信任和口碑，本來是 Anthropic 相對於大廠的優勢。現在自己燒掉了。

我理解商業邏輯。Max 方案 $200 吃到飽，如果拿去跑 agentic loop，實際 API 成本可能是幾千甚至上萬美金。公司本來就在虧錢補貼，當作行銷預算。但行銷預算是有條件的：你要能拿到使用者黏著度、使用數據、口碑傳播。透過第三方工具，這些價值 Anthropic 拿不到。所以他們想把流量逼回官方的 Claude Code。邏輯上說得通，但執行方式就是背刺。你不能先開放讓生態長起來，等大家投入夠深了再改規則。這叫養套殺。

最諷刺的是，我把這整件事拿去跟 Claude 討論。它的分析跟 Theo 講的幾乎一樣。它自己都說這件事處理得很爛，公司的執行沒有展現它被訓練出來的價值觀——考慮後果、對使用者誠實、避免傷害信任。一間強調 AI 安全和對齊的公司，在對待開發者的時候選擇「先斬後奏、被罵才改」。而他們訓練出來的 AI，反而比他們更懂得這樣不對。

我真心覺得，Anthropic 在做這種決策之前，應該先讓 Claude 過濾一遍。不是讓 AI 做決定，而是跑一個基本的 sanity check：「我們打算這樣做，開發者社群會怎麼反應？」Claude 會列出可能的負面輿論、信任損害、更好的執行方式。這不需要什麼特殊技術，把計畫丟進去問一下就好。但他們顯然沒做，或者做了但忽略了。他們花了那麼多資源訓練一個會考慮後果、預測影響的 AI，結果自己做決策的時候連這個最基本的步驟都跳過。

我會繼續用 Claude 嗎？老實說，會。因為它在程式開發上真的很強，目前沒有完全對等的替代品。但這件事讓我學到一課：不要把工作流完全建立在一個規則不透明、執行反覆的平台上。下次他們再搞什麼花樣，我不會意外。而等到開放原始碼模型真的追上來的那天，這些累積的怨氣會一次算總帳。
