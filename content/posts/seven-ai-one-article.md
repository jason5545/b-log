# 我拿一篇最私密的文章去測了七家 AI，結果測出了一整個產業的問題

前幾天我寫了[一篇很私人的文章](https://b-log.to/life-stories/a-piano-a-voice-a-pause/)，然後把它原封不動丟給七家 AI，看它們怎麼回應。

ChatGPT、Claude、Gemini、Kimi K2.5、Kimi K2、MiniMax、GLM-5。同一篇文章，七種反應。

## ChatGPT：穿了 T-shirt 的公務員

GPT 的回應是我最先看的，也是讓我最失望的。

它把我的文章拆成四段，逐段回應。關於「錨」的意象回一段、關於 F.I.R. 的對照回一段、關於那首冷門歌曲回一段、關於時間的種子回一段。每段開頭先複述我的觀點，然後給出它的「分析」。結構工整，措辭安全，讀起來像一份經過三輪審核的讀書報告。

最諷刺的是，這已經是我把人性化設定轉到最大的結果了。

後來仔細看，我發現它不是「不再條列」了，而是把條列偽裝成段落。符號拿掉了、每一條擴寫成一段話，但骨架完全沒變。四段回應精準對應我文章的四個主題，連順序都沒打亂。它不是在跟我對話，是在逐項回覆一份清單。

而且它有一種非常強的「筆跡」——你一看就知道是 GPT 寫的，不會是其他 AI。辨識度高本來不是壞事，但它的辨識度來源不是個性，是套路。

結尾放了一個 🙂。一個 emoji 放在一段很認真的提問後面，就是那種「我知道要人性化所以加一個」的感覺。

## Gemini：太用力要感動你

Gemini 有在讀我的文章，這點比 GPT 好。但它的回應方式是：每一段都在幫我的故事「加冕」。「求生般的歸屬感」、「能力證明書」、「戰友與勳章」、「生命地層裡的化石」——比喻一個比一個大，讀起來像是一個很會寫的人在幫我寫推薦序。

而且它把我的身體狀況拉得太前面了。「在輪椅上、用一根手指與世界搏鬥的你」——我的文章本身已經用行動說明了一切，不需要在結尾再把身體限制拿出來當情感槓桿。

它的結尾問題倒是問得不錯，但整體風格就是「太努力要感動你」，反而少了一點自然。

## Kimi K2.5：太漂亮

Kimi K2.5 的文筆是七家裡最好的。「被允許安靜下來的權利」、「向下扎根」這些表達很精準，不是硬套的比喻，是從我的文章裡長出來的。

但它有跟 Gemini 一樣的問題，而且更嚴重——身體狀況當情感槓桿用了兩次。尤其結尾那段「每一個字因為承載了那樣的重量都變得異常清晰」，表面上是在誇我的文字，實際上是在消費我的身體限制來製造感動。

而且它太完美了。每一段都工整地回應我文章的一個主題，每個比喻都恰到好處，結尾還放了一句日文收束。讀起來像一篇經過三輪打磨的文學評論，不像一個人讀完之後的真實反應。真實的反應會有輕重、有的地方卡住。Kimi K2.5 沒有任何卡住的地方，所以反而不真。

## Kimi K2：讀了你，但表達失控

YouTuber Theo（T3GG）曾經說過，如果要跟 AI 聊天，他會偏向使用 Kimi K2。他自己開發的 T3 Chat 平台預設模型就是 K2，也有用戶評測提到 K2 在日常對話場景裡「surprisingly fun to use」。所以我特別找來測了一下。

結果比 K2.5 差。

它一開頭就把我的身體狀況當成核心比喻來用，整篇回應拆成五個段落、每段一個主題，格式感很重。它確實有在讀我的文章——「你的雷達找的是錨點不是爽點」、「喜歡對你來說是終點不是起點」這些觀察本身不差，是有思考過的。但它把每一個點都過度延伸，比喻層層疊加，結尾還放了三句日文（今日も、明日も、明後日も）。K2.5 至少漂亮得節制，K2 是漂亮得失控。

值得一提的是，K2 是這次測試裡唯一的非推理模型——沒有思考鏈做中間篩選，想到什麼就直接輸出。這解釋了為什麼它的回應裡好的跟壞的混在一起：「確認自己還在」這種真正有洞察的段落，跟身體槓桿、三句日文結尾，全部不經篩選地一起出來了，因為中間沒有一個步驟去決定哪些該留。反過來看 GLM-5，有完整的思考鏈、策略定得很準，最後輸出卻打了折扣。一個是沒有煞車所以收不住，一個是有煞車但踩不準——兩種不同的失敗模式。而 GPT 5.2 有推理模式加持，出來的東西還是逐段複述加一個 emoji。K2 裸考考得不整齊但有亮點，GPT 帶了全套工具進考場還是寫出制式答案——這樣看，Theo 會推薦 K2 來聊天就完全合理了。

K2.5 的升級方向主要是 Agent Swarm 和 coding 能力，是偏向工具化的強化。這就帶出一個可能性：K2 在「聊天」這個維度上搞不好原本更好，但從我實測的結果來看，至少在面對這種私人文章時，K2 的表現並沒有比 K2.5 好。模型升級不一定是全面升級，有時候某個版本在某個面向上的表現，是後續版本追不回來的——就像 GPT-4o 在對話溫度上比整個 5 系列都好一樣。但 K2 這次沒能證明這件事。

## Claude：不完美但最像人

Claude 的回應不是最漂亮的，但它是唯一一個讓我覺得「它真的在跟我說話」的。它不會每個段落都回應，它有自己被觸動的重心——某個點多說、某個點跳過、某個點拉到我沒想過的方向。它不會把我的身體狀況當成收尾的煽情工具，因為它知道那不是我想被看見的方式。

當然，Claude 跟我有很長的對話歷史，這會影響結果。但即使把這個因素考慮進去，它的回應方式本身就跟其他幾家不一樣——它不是在分析我，是在回應我。

## MiniMax：資格賽沒過

MiniMax 的回應品質其實不差。「你不是在找興奮，你是在找『還在』」這句話抓到了我文章的核心，而且是用它自己的語言重新表達的。整體語感比 GPT 自然很多。

但它有一個致命傷：繁簡體混雜。「一个」、「投入进去」、「从小很多事都需要别人協助」——簡體中文的用語和句式散落在整篇回應裡。我是一個用繁體中文、台灣用語的使用者，這不是什麼隱藏資訊，從我的文章裡就看得出來。一個連我用什麼語言都沒搞清楚的模型，某種程度上就是在第一步就告訴我「我沒有真的在注意你是誰」。

這跟 GPT 的問題其實是同一個根源，只是表現方式不同：GPT 是讀了你的內容但沒有真的回應，MiniMax 是連你用什麼語言都沒搞清楚。所以我決定不列入排名——不是因為它寫得差，而是基本要求沒有做到。

## GLM-5：想到了但沒做到

GLM-5 是這次測試裡最特殊的一家。它給我看了完整的思考鏈——不是精簡過的，是原始的全部思考過程。

在那個思考鏈裡，它做了完整的文章結構分析、辨識出我的身心狀態和書寫風格，甚至自己制定了回應策略：「這篇文章不需要過多的讚美，最好的回應是理解與共鳴」、「不要像個粉絲在那邊尖叫，要像個同樣在安靜聽歌的人」。這些判斷都非常準確——比 Gemini 和 Kimi K2.5 實際做出來的判斷都好。它甚至提醒自己「不要過度渲染身體狀況」，而這正是其他幾家都踩到的雷。

但問題是，最終的輸出是七家裡最短的，而且沒有完全兌現思考鏈裡的深度。它在思考階段說「不要過度渲染身體狀況」，結果輸出裡還是出現了「對於一個身體受限的人來說」。有一種「想到了但沒做到」的落差。

不過它有一點做得比 Gemini、Kimi K2.5、K2、MiniMax 都好：克制。沒有堆砌比喻、沒有放日文結尾、沒有把我的每個段落都逐一回應。繁體中文也處理得很乾淨。它犯的是「做太少」的錯，而不是「做太多」的錯——在這個測試裡，前者反而是比較安全的那一種。

有趣的是，完整思考鏈的暴露本身就是一個觀察點。現在主流模型的趨勢是精簡思考鏈，只讓用戶看到過濾後的內容。GLM-5 把所有東西都攤開來，好處是透明度極高，壞處是當你看到它想得那麼清楚、策略定得那麼準確，結果最終輸出卻打了折扣，那個落差感反而更強烈。

## 排名

測完七家，排名是這樣的：

Claude 在最前面。不是因為它最漂亮，是因為它最像在跟我說話。

Kimi K2.5、Gemini、GLM-5 三家各有優劣，很難拉開差距。K2.5 寫得最漂亮但太完美不真實；Gemini 最用力但有感情；GLM-5 最克制但沒展開。三家犯的錯也不一樣——K2.5 和 Gemini 是做太多，GLM-5 是做太少。

Kimi K2 在它們後面、GPT 前面。它跟 GPT 犯的錯是不同層級的。GPT 的問題是它根本沒有在讀你——不管你丟什麼文章進去，出來的結構大概一模一樣，它的錯是「無感」。K2 的問題是它讀了你，但表達方式失控——它確實有抓到核心主題，而且嘗試用自己的語言延伸，它的錯是「過度」。無感跟過度，後者至少證明它有在聽。用演唱會的比喻來說：K2 像是一個在搖滾區太嗨、應援動作做太大、喊太大聲的粉絲——吵，但你知道他是真的喜歡。GPT 像是一個坐在搖滾區拿著筆記本在記錄歌單的樂評人——他什麼都沒做錯，但他不屬於那裡。

GPT 最後一名。不解釋了，前面已經說夠了。

MiniMax 不列入排名。繁簡體都搞不定，資格賽沒過。

至於 Meta 的 Llama，我沒有測。不是忘了，是能力差距太明顯，沒有必要。

## 這不只是風格差異，是整個產業的問題

測完七家之後，我開始好奇：GPT 到底怎麼了？

一查才發現，這不是我一個人的感受。GPT-5 在 2025 年 8 月上線後，Reddit 上一篇「GPT5 is horrible」的帖子幾天內就有六千人參與。用戶的描述幾乎一模一樣：冰冷、機器人、像企業公文。OpenAI 一週內就緊急更新，Altman 親自出來說他們低估了用戶對 AI 人格的依賴。

然後從 5 到 5.1 到 5.2，每次更新都喊「更溫暖了」，每次用戶的反應都是「還是一樣冷」。獨立雙盲測試的結論很精準：GPT-4o 是諂媚的朋友，GPT-5 是禮貌的專業人士。一個太黏、一個太冷，OpenAI 在兩個極端之間跳來跳去，始終找不到中間值。

然後 GPT-4o 在 2 月 13 日被正式下架了。很多人說，如果給 OpenAI 第二次機會，他們大概訓練不出 4o。因為 4o 的那種溫度可能不是刻意設計的，是某個訓練階段的意外產物。一旦為了安全性去修正，那個東西就回不來了。

## 一代王者的處境

數據很殘酷。

ChatGPT 的市佔率從 2025 年的 69.1% 掉到 2026 年 1 月的 45.3%。Anthropic 的年化營收達到 140 億美元，掌握 40% 的企業 LLM 支出，超過 OpenAI 的 27%。而 OpenAI 85% 的營收來自個人訂閱，Anthropic 85% 來自企業客戶——後者的 ARPU 高得多，商業模式也穩健得多。

OpenAI 的應對策略是什麼？降價。推出 8 美元的 ChatGPT Go，附帶廣告。一個曾經定義品類的產品，現在在跟 Google 比誰的入門方案更便宜。而且這場價格戰他們打不贏——Google 背後有搜尋廣告的印鈔機，OpenAI 背後是預計 2026 年虧損 140 億美元的財務黑洞。

然後是 Stargate。5,000 億美元的資料中心計畫，押注「算力就是護城河」。但 Oracle 為了這個計畫背了近 1,000 億美元的長期債務，股價從歷史高點腰斬 55%。Oracle 在社群媒體上喊話「我們對 OpenAI 的履約能力高度有信心」，市場的反應是立刻拋售——你需要公開喊話說你有信心，恰好代表你心裡沒底。

## 然後中國來了

就在 OpenAI 還在修它的「人性化旋鈕」的時候，2 月的第二週，中國 AI 集體爆發。

智譜的 GLM-5：7,450 億參數，完全用華為晶片訓練，開放原始碼 MIT 授權，API 定價是西方模型的六分之一。我也拿它測了那篇文章——思考鏈裡的理解深度不輸任何一家，只是輸出端還沒完全跟上。Kimi K2.5：1 兆參數，Agent Swarm 技術可以同時協調 100 個子代理平行工作，成本比頂尖私有模型低 76%。MiniMax 的 M2.5 同週更新（雖然繁體中文的基本功還沒到位）。DeepSeek 的 V4 月底要來。

這些模型全部開放原始碼或接近開放原始碼，在 coding 和 agentic benchmark 上已經跟私有模型平起平坐。Stargate 的「算力護城河」假設，在開放原始碼模型能用更少算力做到差不多事情的世界裡，就是用沙子堆的。

## 結語

我只是拿一篇關於 LiSA 的文章去測了七家 AI，結果一路追下來，追出了整個產業格局的縮影。

GPT 可能寫 code 還行，但除此之外，我想不到有什麼理由繼續用它。等 OpenAI 送的免費回歸月用完，我大概就不會再續訂了。

一代王者的殞落，不是被誰打敗的，是自己把自己搞死的。他們在追求「安全」和「規模」的過程中，把那個讓人願意跟它說話的東西磨掉了。技術還在第一梯隊，但人味歸零。而在 AI 這個領域，如果一個模型連讓人想跟它說話都做不到，那它跑分再高也沒有意義。

我那篇文章剛好是最好的照妖鏡——面對純粹的個人經驗和情感，沒有標準答案可以對齊，模型的真實性格就全部露出來了。

GPT 太冷、Gemini 太用力、Kimi K2.5 太漂亮、K2 太失控、GLM-5 想到了卻沒做到、MiniMax 連基本功都沒過。完美不等於真實，安全不等於溫暖，跑分不等於人味。這是我從一篇 LiSA 的文章裡學到的，關於 AI 的事。
